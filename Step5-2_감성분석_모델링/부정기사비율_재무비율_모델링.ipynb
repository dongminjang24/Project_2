{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/부정기사비율_재무비율.csv')\n",
    "data.rename(columns={'운전자산총자본비율':'운전자본비율'}, inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "#data.drop(['회사명', '회계년도', '폐지일자'], axis=1, inplace=True)\n",
    "input = data.iloc[:,2:8]\n",
    "target = data.iloc[:,8]\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부실기업의 부정기사 비율 : 29.711582791883014\n",
      "정상기업의 부정기사 비율 : 13.883113450994268\n",
      "부정기사 비율의 차이 : 15.828469340888747\n"
     ]
    }
   ],
   "source": [
    "부실기업부정기사비율 = np.mean(data[data.부실기업여부==1].부정기사비율)\n",
    "정상기업부정기사비율 = np.mean(data[data.부실기업여부==0].부정기사비율)\n",
    "부정기사비율차이 = 부실기업부정기사비율 - 정상기업부정기사비율\n",
    "\n",
    "print(f'부실기업의 부정기사 비율 : {부실기업부정기사비율}')\n",
    "print(f'정상기업의 부정기사 비율 : {정상기업부정기사비율}')\n",
    "print(f'부정기사 비율의 차이 : {부정기사비율차이}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier\n",
    "##### 설명 참고 : https://wooono.tistory.com/97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best roc : 0.9258756395120031\n",
      "best param :  {'gamma': 2, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n",
    "x_test = rs.fit_transform(x_test)\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_param_grid = {'n_estimators' : [100, 200],\n",
    "                'learning_rate' : [0.01, 0.05, 0.1],\n",
    "                'max_depth' : [3, 5, 7],\n",
    "                'gamma' : [0, 1, 2]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, param_grid=xgb_param_grid, scoring='roc_auc', verbose=0, n_jobs=1)\n",
    "xgb_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best roc : {xgb_grid.best_score_}')\n",
    "print('best param : ', xgb_grid.best_params_)\n",
    "\n",
    "## 참고 : https://cjh34544.tistory.com/m/4\n",
    "## http://aispiration.com/model/model-python-xgboost-hyper.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best roc : 0.9432703659976387\n",
      "best param :  {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbswo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dbswo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dbswo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dbswo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dbswo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.9328414         nan 0.94104683        nan 0.94327037\n",
      "        nan 0.94041716        nan 0.93957104]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n",
    "x_test = rs.fit_transform(x_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr_param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "                'penalty' : ['l1', 'l2']}\n",
    "\n",
    "lr_grid = GridSearchCV(lr, param_grid=lr_param_grid, scoring='roc_auc', verbose=0, n_jobs=1)\n",
    "lr_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best roc : {lr_grid.best_score_}')\n",
    "print('best param : ', lr_grid.best_params_)\n",
    "\n",
    "# 참고 : https://wikidocs.net/16594\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best roc : 0.9454348681621407\n",
      "best param :  {'max_depth': 3, 'min_samples_leaf': 16, 'min_samples_split': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n",
    "x_test = rs.fit_transform(x_test)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {'n_estimators' : [100, 200],\n",
    "                'max_depth' : [3, 5, 7],\n",
    "                'min_samples_leaf' : [8, 12, 16],\n",
    "                'min_samples_split' : [8, 16, 20]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid=rf_param_grid, scoring='roc_auc', verbose=0, n_jobs=1)\n",
    "rf_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best roc : {rf_grid.best_score_}')\n",
    "print('best param : ', rf_grid.best_params_)\n",
    "\n",
    "## 참고 : https://techblog-history-younghunjo1.tistory.com/102\n",
    "## https://jaaamj.tistory.com/35\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best roc : 0.9440377804014168\n",
      "best param :  {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n",
    "x_test = rs.fit_transform(x_test)\n",
    "\n",
    "svc = SVC(random_state=42, probability=True)\n",
    "\n",
    "svc_param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "                'gamma' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "svc_grid = GridSearchCV(svc, param_grid=svc_param_grid, scoring='roc_auc', verbose=0, n_jobs=1)\n",
    "svc_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best roc : {svc_grid.best_score_}')\n",
    "print('best param : ', svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8159340659340659\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n",
    "x_test = rs.fit_transform(x_test)\n",
    "\n",
    "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cat.fit(x_train, y_train)\n",
    "pred = cat.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "roc = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://velog.io/@jus6886/Catboost\n",
    "##### https://undeadkwandoll.tistory.com/61\n",
    "##### https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002698429\n",
    "#### CatBoost 설명\n",
    "##### https://dailyheumsi.tistory.com/136\n",
    "##### https://techblog-history-younghunjo1.tistory.com/199\n",
    "##### https://heeya-stupidbutstudying.tistory.com/43?category=950711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Model 비교\n",
    "##### https://medium.com/@divyagera2402/boosting-algorithms-adaboost-gradient-boosting-xgb-light-gbm-and-catboost-e7d2dbc4e4ca\n",
    "##### http://dmqm.korea.ac.kr/activity/seminar/323\n",
    "##### https://hyunlee103.tistory.com/25\n",
    "##### https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
