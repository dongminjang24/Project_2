{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>폐지일자</th>\n",
       "      <th>기사종료시작날짜</th>\n",
       "      <th>종료연도</th>\n",
       "      <th>종료월</th>\n",
       "      <th>종료일</th>\n",
       "      <th>기사시작시작날짜</th>\n",
       "      <th>시작연도</th>\n",
       "      <th>시작월</th>\n",
       "      <th>시작일</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>씨제이이엔엠</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>안랩</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>포스코아이씨티</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네오위즈</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>젬백스&amp;카엘</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>지니뮤직</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>대주전자재료</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>크리스에프앤씨</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>앤디포스</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>에이치엘비</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         회사명       폐지일자   기사종료시작날짜  종료연도 종료월 종료일   기사시작시작날짜  시작연도 시작월 시작일\n",
       "0     씨제이이엔엠 2011-12-31 2011-12-31  2011  12  31 2010-12-31  2010  12  31\n",
       "1         안랩 2011-12-31 2011-12-31  2011  12  31 2010-12-31  2010  12  31\n",
       "2    포스코아이씨티 2011-12-31 2011-12-31  2011  12  31 2010-12-31  2010  12  31\n",
       "3       네오위즈 2011-12-31 2011-12-31  2011  12  31 2010-12-31  2010  12  31\n",
       "4     젬백스&카엘 2011-12-31 2011-12-31  2011  12  31 2010-12-31  2010  12  31\n",
       "..       ...        ...        ...   ...  ..  ..        ...   ...  ..  ..\n",
       "130     지니뮤직 2018-12-31 2018-12-31  2018  12  31 2017-12-31  2017  12  31\n",
       "131   대주전자재료 2018-12-31 2018-12-31  2018  12  31 2017-12-31  2017  12  31\n",
       "132  크리스에프앤씨 2018-12-31 2018-12-31  2018  12  31 2017-12-31  2017  12  31\n",
       "133     앤디포스 2018-12-31 2018-12-31  2018  12  31 2017-12-31  2017  12  31\n",
       "134    에이치엘비 2020-12-31 2020-12-31  2020  12  31 2019-12-31  2019  12  31\n",
       "\n",
       "[135 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "정상기업 = pd.read_csv('./datasets/정상기업크롤링용리스트.csv')\n",
    "정상기업['폐지일자'] = pd.to_datetime(정상기업['폐지일자'])\n",
    "\n",
    "dif_3m = relativedelta(months=3)\n",
    "dif_12m = relativedelta(months=12)\n",
    "\n",
    "정상기업['기사종료시작날짜'] = 정상기업['폐지일자']\n",
    "종료리스트 = 정상기업['기사종료시작날짜'].astype(str).str.split('-')\n",
    "정상기업['종료연도'] = 종료리스트.str.get(0)\n",
    "정상기업['종료월'] = 종료리스트.str.get(1)\n",
    "정상기업['종료일'] = 종료리스트.str.get(2)\n",
    "\n",
    "정상기업['기사시작시작날짜'] = (정상기업['기사종료시작날짜'].apply(lambda x : x - dif_12m))\n",
    "시작리스트 = 정상기업['기사시작시작날짜'].astype(str).str.split('-')\n",
    "정상기업['시작연도'] = 시작리스트.str.get(0)\n",
    "정상기업['시작월'] = 시작리스트.str.get(1)\n",
    "정상기업['시작일'] = 시작리스트.str.get(2)\n",
    "\n",
    "정상기업\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완성본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ = ['기업', '기사발행일', '기사제목', '뉴스기사본문']\n",
    "뉴스_df = pd.DataFrame(columns=column_)\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "회사명_ = 정상기업['회사명'][0]\n",
    "종료연도_ = 정상기업['종료연도']\n",
    "종료월_ = 정상기업['종료월']\n",
    "종료일_ = 정상기업['종료일']\n",
    "시작연도_ = 정상기업['시작연도']\n",
    "시작월_ = 정상기업['시작월']\n",
    "시작일_ = 정상기업['시작일']\n",
    "\n",
    "# start = '2010.01.01'\n",
    "# end = '2010.12.31'\n",
    "# start_= '20100101'\n",
    "# end_ = '20101231'\n",
    "\n",
    "for 기업, 종료연도, 종료월, 종료일, 시작연도, 시작월, 시작일 in  zip(회사명_, 종료연도_, 종료월_, 종료일_, 시작연도_, 시작월_, 시작일_):\n",
    "\n",
    "    start = (시작연도 + '.' + 시작월 + '.' + 시작일)\n",
    "    end = (종료연도 + '.' + 종료월 + '.' + 종료일)\n",
    "    start_= (시작연도 + 시작월 + 시작일)\n",
    "    end_ = (종료연도 + 종료월 + 종료일)\n",
    "\n",
    "    # 나중에 뉴스_df와 concat할 임시 df 생성 및 임시 리스트들 생성\n",
    "    column_ = ['기업', '기사발행일', '기사제목', '뉴스기사본문']\n",
    "    임시_df = pd.DataFrame(columns=column_)    \n",
    "\n",
    "    # 임시_df에 들어갈 리스트 생성\n",
    "    본문리스트 = []\n",
    "    날짜리스트 = []\n",
    "    제목리스트 = []\n",
    "    기업이름 = []\n",
    "\n",
    "    # while 종료 조건으로 쓸 리스트 생성\n",
    "    newslist = []\n",
    "    datelist = []\n",
    "    \n",
    "    page = 1\n",
    "\n",
    "    # 페이지수가 나와있지않으므로 맨끝에 page에 10씩더해서 계속 다음페이지로 이동\n",
    "    while page < 200:\n",
    "\n",
    "        url = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query='+'\"'+기업+'\"'+'&sort=0&photo=0&field=0&pd=3&ds='+start+'&de='+end+'&cluster_rank=19&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from'+start_+'to'+end_+',a:all&start='+str(page)\n",
    "        driver.get(url)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        # a태그중에서 class가 info인 것과 span태그에 class가 info 인 것 가져옴 \n",
    "        news_titles = soup.select(\"a.info\")\n",
    "        dates = soup.select('span.info')\n",
    "\n",
    "        # 네이버기사와 신문사기사 둘다 하이퍼링크가 있을경우는 기사당 news가 2개씩 네이버 기사가 없을 경우는 1개씩만 링크가 추출된다\n",
    "        # 어림잡아 news_titles수가 10개 미만일 경우는 기사의 수가 5개에서 10개 미만이라는 뜻으로 해석하여 10개 이상만 링크와 기사날짜를 추출\n",
    "        if len(news_titles) >= 10:\n",
    "\n",
    "            for news in news_titles:\n",
    "                title = news.attrs['href']\n",
    "                newslist.append(title)\n",
    "\n",
    "            for date in dates:\n",
    "                news_date = date.text\n",
    "                datelist.append(news_date)\n",
    "\n",
    "            # 네이버 검색시 page number가 다음페이지로 갈때마다 1, 11, 21 이렇게 10씩 더해지는데 다음페이지가 없을경우 \n",
    "            # 마지막 기사만을 포함한 같은 페이지를 계속 반환함. 따라서 기사와 날짜 둘 다 중복되서 저장될경우 종료함\n",
    "            if (newslist[-1]==newslist[-2]) & (datelist[-1]==datelist[-2]):\n",
    "                break\n",
    "\n",
    "            page += 10\n",
    "\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 기사수 5개 미만시 break, 기사없는기업 리스트에 저장함\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "    \n",
    "    # sid=101은 네이버 경제기사를 의미하는 듯함. 경제기사만 추출\n",
    "    newslist = [news for news in newslist if 'sid=101' in news]\n",
    "    \n",
    "    # news_titles 뉴스기사 url 리스트가 존재시\n",
    "    if news_titles:\n",
    "\n",
    "        # 뉴스기사 url 자체에서는 text가 안가져와지는 특이사항 발생, 찾아보니 네이버기사는 인터넷에 떠야 페이지가 작동하는? 방식이라함\n",
    "        # 셀레니움을 통해서 뉴스기사 url 주소로 창을 띄움\n",
    "        for news in newslist:\n",
    "            url = news\n",
    "            driver.get(url)\n",
    "            \n",
    "            # 뉴스기사 url에서 본문과 제목, 기사작성날짜를 리스트에 저장함\n",
    "            # 데이터프레임에 직접 행을 지정해주기는 번거로움..\n",
    "            try:\n",
    "\n",
    "                날짜 = driver.find_element_by_xpath('//*[@id=\"ct\"]/div[1]/div[3]/div[1]/div/span').text\n",
    "                날짜리스트.append(날짜)\n",
    "\n",
    "                제목 = driver.find_element_by_xpath('//*[@id=\"ct\"]/div[1]/div[2]/h2').text\n",
    "                제목리스트.append(제목)\n",
    "\n",
    "                본문 = driver.find_element_by_xpath('//*[@id=\"dic_area\"]').text\n",
    "                본문리스트.append(본문)\n",
    "                time.sleep(1)\n",
    "\n",
    "                기업이름.append(기업)\n",
    "            \n",
    "            ## 로딩이 안되서 데이터를 못가져올 경우를 대비해 sleep 3초 주고 다시 시도\n",
    "            except:\n",
    "\n",
    "                time.sleep(3)\n",
    "\n",
    "                try:\n",
    "\n",
    "                    날짜 = driver.find_element_by_xpath('//*[@id=\"ct\"]/div[1]/div[3]/div[1]/div/span').text\n",
    "                    날짜리스트.append(날짜)\n",
    "\n",
    "                    제목 = driver.find_element_by_xpath('//*[@id=\"ct\"]/div[1]/div[2]/h2').text\n",
    "                    제목리스트.append(제목)\n",
    "\n",
    "                    본문 = driver.find_element_by_xpath('//*[@id=\"dic_area\"]').text\n",
    "                    본문리스트.append(본문)\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    기업이름.append(기업)\n",
    "                \n",
    "                # 그래도 데이터를 가져오지 못하는 경우는 페이지에 문제가 있다고 판단하여 PASS\n",
    "                except:\n",
    "\n",
    "                    pass\n",
    "\n",
    "    # 혹시나 뉴스기사 url 리스트가 없을 경우는 pass                \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # 기업별로 가져온 날짜와 본문, 제목, 기업이름을 임시 데이터프레임으로 저장    \n",
    "    임시_df.기사발행일 = 날짜리스트\n",
    "    임시_df.뉴스기사본문 = 본문리스트\n",
    "    임시_df.기사제목 = 제목리스트\n",
    "    임시_df.기업 = 기업이름\n",
    "    \n",
    "    # 임시 데이터프레임을 뉴스 데이터프레임에 아래로 결합\n",
    "    뉴스_df = pd.concat([뉴스_df, 임시_df])\n",
    "\n",
    "# 앞에서 while 종료 조건이 같은 기사 2번저장인데 이럴 경우 중복으로 저장이 되야 종료되기때문에\n",
    "# 중복기사 행 제거\n",
    "뉴스_df.drop_duplicates(inplace=True)\n",
    "뉴스_df.to_csv('../Step3_1_뉴스전처리/news/정상기업뉴스.csv', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fa163922eb0b3709bbb5d8082b2465c9de796dbaacca80cbaa600e7fff3e4fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
